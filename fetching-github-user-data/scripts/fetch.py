#!/usr/bin/env python3
"""
GitHub ç”¨æˆ·æ•°æ®è·å–å·¥å…·

é€šè¿‡ GitHub API è·å–æŒ‡å®šç”¨æˆ·çš„æ‰€æœ‰å…¬å¼€æ•°æ®ï¼Œå¹¶ä»¥ç›®å½•/æ–‡ä»¶çš„æ–¹å¼å­˜å‚¨åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿã€‚

ä½¿ç”¨æ–¹æ³•:
    python fetch_github_user_data.py <username> [--token <github_token>] [--output <output_dir>]

ç¤ºä¾‹:
    python fetch_github_user_data.py torvalds --token ghp_xxxx --output ./github_data
"""

import argparse
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional
from urllib.parse import parse_qs, urlparse

import requests


class GitHubUserDataFetcher:
    """GitHub ç”¨æˆ·æ•°æ®è·å–å™¨"""

    def __init__(self, username: str, token: Optional[str] = None, output_dir: str = "./github_user_data"):
        """
        åˆå§‹åŒ–

        Args:
            username: GitHub ç”¨æˆ·å
            token: GitHub Personal Access Tokenï¼ˆå¯é€‰ï¼‰
            output_dir: è¾“å‡ºç›®å½•
        """
        self.username = username
        self.token = token
        self.output_dir = Path(output_dir) / username
        self.base_url = "https://api.github.com"
        self.session = requests.Session()

        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            "Accept": "application/vnd.github+json",
            "X-GitHub-Api-Version": "2022-11-28"
        })

        if token:
            self.session.headers.update({
                "Authorization": f"Bearer {token}"
            })

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "requests_made": 0,
            "data_fetched": {},
            "errors": []
        }

    def _make_request(self, endpoint: str, params: Optional[Dict] = None) -> requests.Response:
        """
        å‘èµ· API è¯·æ±‚

        Args:
            endpoint: API ç«¯ç‚¹ï¼ˆä¸åŒ…å« base_urlï¼‰
            params: æŸ¥è¯¢å‚æ•°

        Returns:
            Response å¯¹è±¡
        """
        url = f"{self.base_url}{endpoint}"
        self.stats["requests_made"] += 1

        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            return response
        except requests.exceptions.RequestException as e:
            error_msg = f"è¯·æ±‚å¤±è´¥: {endpoint} - {str(e)}"
            self.stats["errors"].append(error_msg)
            print(f"âŒ {error_msg}", file=sys.stderr)
            raise

    def _fetch_paginated_data(self, endpoint: str, params: Optional[Dict] = None) -> List[Dict]:
        """
        è·å–åˆ†é¡µæ•°æ®

        Args:
            endpoint: API ç«¯ç‚¹
            params: æŸ¥è¯¢å‚æ•°

        Returns:
            æ‰€æœ‰åˆ†é¡µæ•°æ®çš„åˆ—è¡¨
        """
        all_data = []
        page = 1
        per_page = 100

        if params is None:
            params = {}

        params["per_page"] = per_page

        while True:
            params["page"] = page
            print(f"  æ­£åœ¨è·å–ç¬¬ {page} é¡µ...")

            try:
                response = self._make_request(endpoint, params)
                data = response.json()

                if not data:
                    break

                all_data.extend(data)

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ
                link_header = response.headers.get("Link", "")
                if 'rel="next"' not in link_header:
                    break

                page += 1

            except Exception as e:
                print(f"  è·å–ç¬¬ {page} é¡µæ—¶å‡ºé”™: {str(e)}", file=sys.stderr)
                break

        return all_data

    def _save_json(self, data: Any, filepath: Path):
        """ä¿å­˜ JSON æ•°æ®åˆ°æ–‡ä»¶"""
        filepath.parent.mkdir(parents=True, exist_ok=True)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"  âœ“ å·²ä¿å­˜åˆ°: {filepath}")

    def fetch_profile(self) -> Dict:
        """è·å–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯"""
        print(f"\nğŸ“ è·å–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯...")
        response = self._make_request(f"/users/{self.username}")
        profile = response.json()

        self._save_json(profile, self.output_dir / "profile.json")
        self.stats["data_fetched"]["profile"] = True
        return profile

    def fetch_repositories(self):
        """è·å–ç”¨æˆ·ä»“åº“"""
        print(f"\nğŸ“¦ è·å–ç”¨æˆ·ä»“åº“...")
        repos = self._fetch_paginated_data(
            f"/users/{self.username}/repos",
            {"type": "all", "sort": "updated"}
        )

        # ä¿å­˜ä»“åº“åˆ—è¡¨æ‘˜è¦
        repos_summary = [{
            "name": repo["name"],
            "full_name": repo["full_name"],
            "description": repo["description"],
            "stars": repo["stargazers_count"],
            "forks": repo["forks_count"],
            "language": repo["language"],
            "updated_at": repo["updated_at"],
            "html_url": repo["html_url"]
        } for repo in repos]

        self._save_json(repos_summary, self.output_dir / "repositories" / "list.json")

        # ä¿å­˜æ¯ä¸ªä»“åº“çš„è¯¦ç»†ä¿¡æ¯
        details_dir = self.output_dir / "repositories" / "details"
        for repo in repos:
            repo_name = repo["name"]
            self._save_json(repo, details_dir / f"{repo_name}.json")

        self.stats["data_fetched"]["repositories"] = len(repos)
        print(f"  å…±è·å– {len(repos)} ä¸ªä»“åº“")

    def fetch_gists(self):
        """è·å–ç”¨æˆ· Gists"""
        print(f"\nğŸ“„ è·å–ç”¨æˆ· Gists...")
        gists = self._fetch_paginated_data(f"/users/{self.username}/gists")

        # ä¿å­˜ gists åˆ—è¡¨
        gists_summary = [{
            "id": gist["id"],
            "description": gist["description"],
            "public": gist["public"],
            "files": list(gist["files"].keys()),
            "created_at": gist["created_at"],
            "updated_at": gist["updated_at"],
            "html_url": gist["html_url"]
        } for gist in gists]

        self._save_json(gists_summary, self.output_dir / "gists" / "list.json")

        # ä¿å­˜æ¯ä¸ª gist çš„è¯¦ç»†ä¿¡æ¯
        details_dir = self.output_dir / "gists" / "details"
        for gist in gists:
            gist_id = gist["id"]
            self._save_json(gist, details_dir / f"{gist_id}.json")

        self.stats["data_fetched"]["gists"] = len(gists)
        print(f"  å…±è·å– {len(gists)} ä¸ª Gists")

    def fetch_starred(self):
        """è·å–ç”¨æˆ· starred çš„ä»“åº“"""
        print(f"\nâ­ è·å– Starred ä»“åº“...")
        starred = self._fetch_paginated_data(
            f"/users/{self.username}/starred",
            {"sort": "created"}
        )

        # ä¿å­˜ starred ä»“åº“åˆ—è¡¨
        starred_summary = [{
            "name": repo["name"],
            "full_name": repo["full_name"],
            "description": repo["description"],
            "stars": repo["stargazers_count"],
            "language": repo["language"],
            "html_url": repo["html_url"]
        } for repo in starred]

        self._save_json(starred_summary, self.output_dir / "starred" / "repositories.json")
        self.stats["data_fetched"]["starred"] = len(starred)
        print(f"  å…±è·å– {len(starred)} ä¸ª Starred ä»“åº“")

    def fetch_followers(self):
        """è·å–ç”¨æˆ·çš„ Followers"""
        print(f"\nğŸ‘¥ è·å– Followers...")
        followers = self._fetch_paginated_data(f"/users/{self.username}/followers")

        # ä¿å­˜ followers åˆ—è¡¨
        followers_summary = [{
            "login": user["login"],
            "id": user["id"],
            "avatar_url": user["avatar_url"],
            "html_url": user["html_url"],
            "type": user["type"]
        } for user in followers]

        self._save_json(followers_summary, self.output_dir / "social" / "followers.json")
        self.stats["data_fetched"]["followers"] = len(followers)
        print(f"  å…±è·å– {len(followers)} ä¸ª Followers")

    def fetch_following(self):
        """è·å–ç”¨æˆ· Following çš„äºº"""
        print(f"\nğŸ‘¤ è·å– Following...")
        following = self._fetch_paginated_data(f"/users/{self.username}/following")

        # ä¿å­˜ following åˆ—è¡¨
        following_summary = [{
            "login": user["login"],
            "id": user["id"],
            "avatar_url": user["avatar_url"],
            "html_url": user["html_url"],
            "type": user["type"]
        } for user in following]

        self._save_json(following_summary, self.output_dir / "social" / "following.json")
        self.stats["data_fetched"]["following"] = len(following)
        print(f"  å…±è·å– {len(following)} ä¸ª Following")

    def fetch_organizations(self):
        """è·å–ç”¨æˆ·æ‰€å±çš„ç»„ç»‡"""
        print(f"\nğŸ¢ è·å–ç”¨æˆ·ç»„ç»‡...")
        try:
            orgs = self._fetch_paginated_data(f"/users/{self.username}/orgs")

            # ä¿å­˜ç»„ç»‡åˆ—è¡¨
            orgs_summary = [{
                "login": org["login"],
                "id": org["id"],
                "description": org.get("description"),
                "avatar_url": org["avatar_url"],
                "html_url": f"https://github.com/{org['login']}"
            } for org in orgs]

            self._save_json(orgs_summary, self.output_dir / "organizations.json")
            self.stats["data_fetched"]["organizations"] = len(orgs)
            print(f"  å…±è·å– {len(orgs)} ä¸ªç»„ç»‡")
        except Exception as e:
            print(f"  è·å–ç»„ç»‡å¤±è´¥: {str(e)}", file=sys.stderr)
            self.stats["data_fetched"]["organizations"] = 0

    def fetch_events(self):
        """è·å–ç”¨æˆ·çš„å…¬å¼€æ´»åŠ¨äº‹ä»¶"""
        print(f"\nğŸ“… è·å–å…¬å¼€æ´»åŠ¨äº‹ä»¶...")
        try:
            events = self._fetch_paginated_data(f"/users/{self.username}/events/public")

            # ä¿å­˜äº‹ä»¶åˆ—è¡¨ï¼ˆåªä¿å­˜æœ€è¿‘çš„ï¼Œå› ä¸º API é™åˆ¶æœ€å¤š 300 æ¡ï¼‰
            events_summary = [{
                "id": event["id"],
                "type": event["type"],
                "repo": event["repo"]["name"],
                "created_at": event["created_at"],
                "public": event["public"]
            } for event in events]

            self._save_json(events_summary, self.output_dir / "events" / "public_events.json")
            self.stats["data_fetched"]["events"] = len(events)
            print(f"  å…±è·å– {len(events)} ä¸ªå…¬å¼€äº‹ä»¶ï¼ˆæœ€è¿‘ 30 å¤©å†…ï¼‰")
        except Exception as e:
            print(f"  è·å–äº‹ä»¶å¤±è´¥: {str(e)}", file=sys.stderr)
            self.stats["data_fetched"]["events"] = 0

    def fetch_subscriptions(self):
        """è·å–ç”¨æˆ·è®¢é˜…çš„ä»“åº“"""
        print(f"\nğŸ”” è·å–è®¢é˜…çš„ä»“åº“...")
        try:
            # æ³¨æ„ï¼šè¿™ä¸ªç«¯ç‚¹å¯èƒ½éœ€è¦è®¤è¯ï¼Œå¹¶ä¸”åªèƒ½è·å–è®¤è¯ç”¨æˆ·è‡ªå·±çš„è®¢é˜…
            subscriptions = self._fetch_paginated_data(f"/users/{self.username}/subscriptions")

            subscriptions_summary = [{
                "name": repo["name"],
                "full_name": repo["full_name"],
                "description": repo["description"],
                "html_url": repo["html_url"]
            } for repo in subscriptions]

            self._save_json(subscriptions_summary, self.output_dir / "subscriptions.json")
            self.stats["data_fetched"]["subscriptions"] = len(subscriptions)
            print(f"  å…±è·å– {len(subscriptions)} ä¸ªè®¢é˜…")
        except Exception as e:
            print(f"  è·å–è®¢é˜…å¤±è´¥ï¼ˆå¯èƒ½éœ€è¦è®¤è¯ï¼‰: {str(e)}", file=sys.stderr)
            self.stats["data_fetched"]["subscriptions"] = 0

    def _make_graphql_request(self, query: str) -> Dict:
        """
        å‘èµ· GraphQL API è¯·æ±‚

        Args:
            query: GraphQL æŸ¥è¯¢è¯­å¥

        Returns:
            å“åº”æ•°æ®
        """
        url = "https://api.github.com/graphql"
        self.stats["requests_made"] += 1

        try:
            response = self.session.post(url, json={"query": query}, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            error_msg = f"GraphQL è¯·æ±‚å¤±è´¥: {str(e)}"
            self.stats["errors"].append(error_msg)
            print(f"âŒ {error_msg}", file=sys.stderr)
            raise

    def fetch_contribution_calendar(self):
        """è·å–ç”¨æˆ·è´¡çŒ®æ—¥å†ï¼ˆä½¿ç”¨ GraphQL APIï¼‰"""
        print(f"\nğŸ“Š è·å–è´¡çŒ®æ—¥å†...")
        try:
            query = """
            {
              user(login: "%s") {
                contributionsCollection {
                  contributionCalendar {
                    totalContributions
                    weeks {
                      contributionDays {
                        contributionCount
                        date
                        weekday
                      }
                    }
                  }
                  restrictedContributionsCount
                }
              }
            }
            """ % self.username

            result = self._make_graphql_request(query)

            if "data" in result and result["data"]["user"]:
                contribution_data = result["data"]["user"]["contributionsCollection"]
                self._save_json(contribution_data, self.output_dir / "contributions" / "calendar.json")

                total = contribution_data["contributionCalendar"]["totalContributions"]
                self.stats["data_fetched"]["contribution_calendar"] = total
                print(f"  å…±è·å– {total} æ¬¡è´¡çŒ®è®°å½•")
            else:
                print(f"  è·å–è´¡çŒ®æ—¥å†å¤±è´¥", file=sys.stderr)
                self.stats["data_fetched"]["contribution_calendar"] = 0
        except Exception as e:
            print(f"  è·å–è´¡çŒ®æ—¥å†å¤±è´¥: {str(e)}", file=sys.stderr)
            self.stats["data_fetched"]["contribution_calendar"] = 0

    def fetch_pull_requests(self):
        """è·å–ç”¨æˆ·åˆ›å»ºçš„ Pull Requests"""
        print(f"\nğŸ”€ è·å– Pull Requests...")
        try:
            # ä½¿ç”¨ Search API æœç´¢ç”¨æˆ·åˆ›å»ºçš„ PR
            response = self._make_request(
                "/search/issues",
                {"q": f"author:{self.username} type:pr", "per_page": 100, "sort": "created", "order": "desc"}
            )
            search_result = response.json()
            total_count = search_result.get("total_count", 0)

            # è·å–å‰ 100 ä¸ª PR çš„è¯¦ç»†ä¿¡æ¯
            prs = search_result.get("items", [])
            prs_summary = [{
                "title": pr["title"],
                "state": pr["state"],
                "created_at": pr["created_at"],
                "updated_at": pr["updated_at"],
                "closed_at": pr.get("closed_at"),
                "repository": pr["repository_url"].split("/")[-2:],
                "html_url": pr["html_url"],
                "comments": pr.get("comments", 0),
                "labels": [label["name"] for label in pr.get("labels", [])]
            } for pr in prs]

            self._save_json({
                "total_count": total_count,
                "fetched_count": len(prs),
                "pull_requests": prs_summary
            }, self.output_dir / "pull_requests" / "created.json")

            self.stats["data_fetched"]["pull_requests"] = total_count
            print(f"  å…±æ‰¾åˆ° {total_count} ä¸ª PRï¼Œå·²ä¿å­˜å‰ {len(prs)} ä¸ªè¯¦æƒ…")
        except Exception as e:
            print(f"  è·å– Pull Requests å¤±è´¥: {str(e)}", file=sys.stderr)
            self.stats["data_fetched"]["pull_requests"] = 0

    def fetch_issues(self):
        """è·å–ç”¨æˆ·åˆ›å»ºçš„ Issues"""
        print(f"\nğŸ› è·å– Issues...")
        try:
            # ä½¿ç”¨ Search API æœç´¢ç”¨æˆ·åˆ›å»ºçš„ issue
            response = self._make_request(
                "/search/issues",
                {"q": f"author:{self.username} type:issue", "per_page": 100, "sort": "created", "order": "desc"}
            )
            search_result = response.json()
            total_count = search_result.get("total_count", 0)

            # è·å–å‰ 100 ä¸ª issue çš„è¯¦ç»†ä¿¡æ¯
            issues = search_result.get("items", [])
            issues_summary = [{
                "title": issue["title"],
                "state": issue["state"],
                "created_at": issue["created_at"],
                "updated_at": issue["updated_at"],
                "closed_at": issue.get("closed_at"),
                "repository": issue["repository_url"].split("/")[-2:],
                "html_url": issue["html_url"],
                "comments": issue.get("comments", 0),
                "labels": [label["name"] for label in issue.get("labels", [])]
            } for issue in issues]

            self._save_json({
                "total_count": total_count,
                "fetched_count": len(issues),
                "issues": issues_summary
            }, self.output_dir / "issues" / "created.json")

            self.stats["data_fetched"]["issues"] = total_count
            print(f"  å…±æ‰¾åˆ° {total_count} ä¸ª Issueï¼Œå·²ä¿å­˜å‰ {len(issues)} ä¸ªè¯¦æƒ…")
        except Exception as e:
            print(f"  è·å– Issues å¤±è´¥: {str(e)}", file=sys.stderr)
            self.stats["data_fetched"]["issues"] = 0

    def fetch_language_stats(self):
        """è·å–ç”¨æˆ·çš„ç¼–ç¨‹è¯­è¨€ç»Ÿè®¡"""
        print(f"\nğŸ’» ç»Ÿè®¡ç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ...")
        try:
            # è¯»å–å·²ä¿å­˜çš„ä»“åº“æ•°æ®
            repos_dir = self.output_dir / "repositories" / "details"
            if not repos_dir.exists():
                print("  éœ€è¦å…ˆè·å–ä»“åº“æ•°æ®", file=sys.stderr)
                return

            language_stats = {}
            total_size = 0

            # éå†æ‰€æœ‰ä»“åº“ï¼Œç»Ÿè®¡è¯­è¨€
            for repo_file in repos_dir.glob("*.json"):
                with open(repo_file, 'r', encoding='utf-8') as f:
                    repo = json.load(f)
                    language = repo.get("language")
                    size = repo.get("size", 0)

                    if language:
                        if language not in language_stats:
                            language_stats[language] = {
                                "repo_count": 0,
                                "total_size_kb": 0
                            }
                        language_stats[language]["repo_count"] += 1
                        language_stats[language]["total_size_kb"] += size
                        total_size += size

            # è®¡ç®—ç™¾åˆ†æ¯”
            for lang in language_stats:
                language_stats[lang]["percentage"] = round(
                    (language_stats[lang]["total_size_kb"] / total_size * 100) if total_size > 0 else 0,
                    2
                )

            # æ’åº
            sorted_languages = dict(
                sorted(language_stats.items(), key=lambda x: x[1]["total_size_kb"], reverse=True)
            )

            self._save_json({
                "languages": sorted_languages,
                "total_size_kb": total_size,
                "language_count": len(sorted_languages)
            }, self.output_dir / "statistics" / "languages.json")

            self.stats["data_fetched"]["language_stats"] = len(sorted_languages)
            print(f"  å…±ç»Ÿè®¡ {len(sorted_languages)} ç§ç¼–ç¨‹è¯­è¨€")
        except Exception as e:
            print(f"  ç»Ÿè®¡ç¼–ç¨‹è¯­è¨€å¤±è´¥: {str(e)}", file=sys.stderr)
            self.stats["data_fetched"]["language_stats"] = 0

    def fetch_repository_stats(self):
        """è·å–ä»“åº“çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“ˆ è·å–ä»“åº“ç»Ÿè®¡ä¿¡æ¯...")
        try:
            # è¯»å–å·²ä¿å­˜çš„ä»“åº“åˆ—è¡¨
            repos_list_file = self.output_dir / "repositories" / "list.json"
            if not repos_list_file.exists():
                print("  éœ€è¦å…ˆè·å–ä»“åº“æ•°æ®", file=sys.stderr)
                return

            with open(repos_list_file, 'r', encoding='utf-8') as f:
                repos = json.load(f)

            stats_summary = {
                "total_stars": 0,
                "total_forks": 0,
                "total_watchers": 0,
                "total_repos": len(repos),
                "by_language": {}
            }

            # ç»Ÿè®¡æ‰€æœ‰ä»“åº“çš„æ•°æ®
            for repo in repos:
                stats_summary["total_stars"] += repo.get("stars", 0)
                stats_summary["total_forks"] += repo.get("forks", 0)

                language = repo.get("language")
                if language:
                    if language not in stats_summary["by_language"]:
                        stats_summary["by_language"][language] = {
                            "repos": 0,
                            "stars": 0,
                            "forks": 0
                        }
                    stats_summary["by_language"][language]["repos"] += 1
                    stats_summary["by_language"][language]["stars"] += repo.get("stars", 0)
                    stats_summary["by_language"][language]["forks"] += repo.get("forks", 0)

            self._save_json(stats_summary, self.output_dir / "statistics" / "repositories.json")
            self.stats["data_fetched"]["repository_stats"] = True
            print(f"  æ€»è®¡: {stats_summary['total_stars']} Stars, {stats_summary['total_forks']} Forks")
        except Exception as e:
            print(f"  è·å–ä»“åº“ç»Ÿè®¡å¤±è´¥: {str(e)}", file=sys.stderr)
            self.stats["data_fetched"]["repository_stats"] = False

    def save_metadata(self):
        """ä¿å­˜å…ƒæ•°æ®"""
        print(f"\nğŸ’¾ ä¿å­˜å…ƒæ•°æ®...")
        metadata = {
            "username": self.username,
            "fetched_at": datetime.now().isoformat(),
            "output_directory": str(self.output_dir),
            "statistics": self.stats,
            "api_version": "2022-11-28"
        }

        self._save_json(metadata, self.output_dir / "metadata.json")

    def fetch_all(self):
        """è·å–æ‰€æœ‰æ•°æ®"""
        print(f"ğŸš€ å¼€å§‹è·å– GitHub ç”¨æˆ· '{self.username}' çš„æ•°æ®...\n")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ä¾æ¬¡è·å–å„ç±»æ•°æ®
        try:
            # åŸºç¡€æ•°æ®
            self.fetch_profile()
            self.fetch_repositories()
            self.fetch_gists()
            self.fetch_starred()

            # ç¤¾äº¤æ•°æ®
            self.fetch_followers()
            self.fetch_following()
            self.fetch_organizations()

            # æ´»åŠ¨æ•°æ®
            self.fetch_events()
            self.fetch_subscriptions()

            # è´¡çŒ®æ•°æ®ï¼ˆéœ€è¦ tokenï¼Œä½¿ç”¨ GraphQLï¼‰
            if self.token:
                self.fetch_contribution_calendar()
            else:
                print("\nâš ï¸  è·³è¿‡è´¡çŒ®æ—¥å†è·å–ï¼ˆéœ€è¦ Personal Access Tokenï¼‰")

            # åä½œæ•°æ®
            self.fetch_pull_requests()
            self.fetch_issues()

            # ç»Ÿè®¡æ•°æ®ï¼ˆä¾èµ–å‰é¢è·å–çš„æ•°æ®ï¼‰
            self.fetch_language_stats()
            self.fetch_repository_stats()

        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        except Exception as e:
            print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}", file=sys.stderr)
        finally:
            # ä¿å­˜å…ƒæ•°æ®
            self.save_metadata()

            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            self.print_summary()

    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æ•°æ®è·å–å®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯:")
        print("=" * 60)
        print(f"æ€»å…±å‘èµ·çš„ API è¯·æ±‚æ•°: {self.stats['requests_made']}")
        print(f"\nå·²è·å–çš„æ•°æ®:")
        for key, value in self.stats['data_fetched'].items():
            if isinstance(value, int):
                print(f"  - {key}: {value} æ¡")
            else:
                print(f"  - {key}: âœ“")

        if self.stats['errors']:
            print(f"\nâš ï¸  é”™è¯¯æ•°: {len(self.stats['errors'])}")
            for error in self.stats['errors'][:5]:  # åªæ˜¾ç¤ºå‰ 5 ä¸ªé”™è¯¯
                print(f"  - {error}")

        print(f"\næ•°æ®å·²ä¿å­˜åˆ°: {self.output_dir}")
        print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="è·å– GitHub ç”¨æˆ·çš„æ‰€æœ‰å…¬å¼€æ•°æ®å¹¶ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è·å–ç”¨æˆ·æ•°æ®ï¼ˆä¸ä½¿ç”¨ tokenï¼‰
  python fetch_github_user_data.py torvalds

  # ä½¿ç”¨ Personal Access Tokenï¼ˆå¯ä»¥æé«˜ rate limitï¼‰
  python fetch_github_user_data.py torvalds --token ghp_xxxxxxxxxxxx

  # æŒ‡å®šè¾“å‡ºç›®å½•
  python fetch_github_user_data.py torvalds --output ./my_data

  # ä»ç¯å¢ƒå˜é‡è¯»å– token
  export GITHUB_TOKEN=ghp_xxxxxxxxxxxx
  python fetch_github_user_data.py torvalds
        """
    )

    parser.add_argument(
        "username",
        help="GitHub ç”¨æˆ·å"
    )

    parser.add_argument(
        "-t", "--token",
        help="GitHub Personal Access Tokenï¼ˆå¯é€‰ï¼Œå¯ä»¥ä»ç¯å¢ƒå˜é‡ GITHUB_TOKEN è¯»å–ï¼‰",
        default=os.environ.get("GITHUB_TOKEN")
    )

    parser.add_argument(
        "-o", "--output",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./github_user_dataï¼‰",
        default="./github_user_data"
    )

    args = parser.parse_args()

    # åˆ›å»º fetcher å¹¶æ‰§è¡Œ
    fetcher = GitHubUserDataFetcher(
        username=args.username,
        token=args.token,
        output_dir=args.output
    )

    fetcher.fetch_all()


if __name__ == "__main__":
    main()
